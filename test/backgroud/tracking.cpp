//opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include "opencv2/objdetect/objdetect.hpp"
#include "opencv2/video/tracking.hpp"
//C
#include <stdio.h>
#include "dtw.h"
//C++
#include <iostream>
#include <sstream>
using namespace cv;
using namespace std;

#define BOX_SIZE  256
// #define BOX_SIZE  256


// Global variables
Mat frame; //current frame
Rect target_box;
Mat target_frame; //current frame
Mat target_frame_gray;
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

Mat flow;
// some faster than mat image container
UMat flowUmat, prevgray;

Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
char keyboard; //input from keyboard
void help();
void processVideo(char* videoFilename);
void processImages(char* firstFrameFilename);
void help()
{
    cout
    << "--------------------------------------------------------------------------" << endl
    << "This program shows how to use background subtraction methods provided by "  << endl
    << " OpenCV. You can process both videos (-vid) and images (-img)."             << endl
                                                                                    << endl
    << "Usage:"                                                                     << endl
    << "./bg_sub {-vid <video filename>|-img <image filename>}"                     << endl
    << "for example: ./bg_sub -vid video.avi"                                       << endl
    << "or: ./bg_sub -img /data/images/1.png"                                       << endl
    << "--------------------------------------------------------------------------" << endl
    << endl;
}
int main(int argc, char* argv[])
{
    //print help information
    help();
    //check for the input parameter correctness
    if(argc != 3) {
        cerr <<"Incorret input list" << endl;
        cerr <<"exiting..." << endl;
        return EXIT_FAILURE;
    }
    //create GUI windows
    namedWindow("Frame");
    namedWindow("FG Mask MOG 2");
    //create Background Subtractor objects
    pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach
    if(strcmp(argv[1], "-vid") == 0) {
        //input data coming from a video
        processVideo(argv[2]);
    } else {
        //error in reading input parameters
        cerr <<"Please, check the input parameters." << endl;
        cerr <<"Exiting..." << endl;
        return EXIT_FAILURE;
    }
    //destroy GUI windows
    destroyAllWindows();
    return EXIT_SUCCESS;
}

Mat kernel = getStructuringElement(MORPH_ELLIPSE,Size(3,3));
vector<Mat> shape_descriptors;

void cal_shape_descriptor(Mat fgMaskMOG2, Mat &shape_descriptor)
{
    for (int y = 0; y < fgMaskMOG2.rows; y += 8) {
        for (int x = 0; x < fgMaskMOG2.cols; x += 8)
        {
            Mat patch = fgMaskMOG2(Rect(x, y, 8, 8));

            int count = 0;
            for (int n = 0; n < patch.rows; n ++) {
                for (int m = 0; m < patch.cols; m ++)
                {
                    if(patch.at<uchar>(n, m) != 0)
                        count++;
                }
            }
            //cout << count << ' ';
            shape_descriptor.at<float>(y >> 3, x >> 3) = count;
        }
    }

    // L2 normalize
    normalize(shape_descriptor, shape_descriptor, 1, 0, NORM_L2);
}

void cal_motion_descriptor(Mat flow, Mat &motion_descriptor) {
    Mat fxp(flow.size(), CV_32FC1, Scalar(0));
    Mat fxm(flow.size(), CV_32FC1, Scalar(0));
    Mat fyp(flow.size(), CV_32FC1, Scalar(0));
    Mat fym(flow.size(), CV_32FC1, Scalar(0));

    for (int y = 0; y < flow.rows; y ++) {
        for (int x = 0; x < flow.cols; x ++)
        {
    // if(flow.at<Point2f>(y, x).x >= 1.0 || flow.at<Point2f>(y, x).y >= 1.0 )
            // cout << '('<< flow.at<Point2f>(y, x).x << ',' << flow.at<Point2f>(y, x).y << ')'<< ' ';

            float fx = flow.at<Point2f>(y, x).x;
            if (fx > 0)
            {
                fxp.at<float>(y, x) =  fx;
                fxm.at<float>(y, x) =  0;
            } else {
                fxp.at<float>(y, x) =  0;
                fxm.at<float>(y, x) =  abs(fx);
            }

            float fy = flow.at<Point2f>(y, x).y;
            if (fy > 0)
            {
                fyp.at<float>(y, x) =  fy;
                fym.at<float>(y, x) =  0;
            } else {
                fyp.at<float>(y, x) =  0;
                fym.at<float>(y, x) =  abs(fy);
            }
        }
    }

    float THRESHOLD_M = 0.5;

    // Add threashold to eliminate noise
    threshold(fxp, fxp, THRESHOLD_M, 1000.0, 3);
    threshold(fxm, fxm, THRESHOLD_M, 1000.0, 3);
    threshold(fyp, fyp, THRESHOLD_M, 1000.0, 3);
    threshold(fym, fym, THRESHOLD_M, 1000.0, 3);

    // BF + -
    GaussianBlur( fxp, fxp, Size(3,3), 0, 0, BORDER_DEFAULT );
    GaussianBlur( fxm, fxm, Size(3,3), 0, 0, BORDER_DEFAULT );
    GaussianBlur( fyp, fyp, Size(3,3), 0, 0, BORDER_DEFAULT );
    GaussianBlur( fyp, fyp, Size(3,3), 0, 0, BORDER_DEFAULT );

    // QBF + -
    Mat fxp_bq(Size(BOX_SIZE >> 4, BOX_SIZE >> 4), CV_32FC1, Scalar(0));
    Mat fxm_bq(Size(BOX_SIZE >> 4, BOX_SIZE >> 4), CV_32FC1, Scalar(0));
    Mat fyp_bq(Size(BOX_SIZE >> 4, BOX_SIZE >> 4), CV_32FC1, Scalar(0));
    Mat fym_bq(Size(BOX_SIZE >> 4, BOX_SIZE >> 4), CV_32FC1, Scalar(0));

    // imshow("fxp_bq", fxp);
    // imshow("fxm_bq", fxm);
    // imshow("fyp_bq", fyp);
    // imshow("fym_bq", fym);

    for (int y = 0; y < flow.rows; y += BOX_SIZE >> 3) {
        for (int x = 0; x < flow.cols; x += BOX_SIZE >> 3)
        {
            Mat patch[4];
            patch[0] = fxp(Rect(x, y, BOX_SIZE >> 3, BOX_SIZE >> 3));
            patch[1] = fxm(Rect(x, y, BOX_SIZE >> 3, BOX_SIZE >> 3));
            patch[2] = fyp(Rect(x, y, BOX_SIZE >> 3, BOX_SIZE >> 3));
            patch[3] = fym(Rect(x, y, BOX_SIZE >> 3, BOX_SIZE >> 3));

            float sum[4] = {0,0,0,0};
            for (int n = 0; n < BOX_SIZE >> 3; n ++) {
                for (int m = 0; m < BOX_SIZE >> 3; m ++)
                {
                    sum[0] += patch[0].at<float>(n, m);
                    sum[1] += patch[1].at<float>(n, m);
                    sum[2] += patch[2].at<float>(n, m);
                    sum[3] += patch[3].at<float>(n, m);
                }
            }

            float area = ((BOX_SIZE * BOX_SIZE) >> 6);
            fxp_bq.at<float>(y / (BOX_SIZE >> 3), x / (BOX_SIZE >> 3)) = sum[0] / area;
            fxm_bq.at<float>(y / (BOX_SIZE >> 3), x / (BOX_SIZE >> 3)) = sum[1] / area;
            fyp_bq.at<float>(y / (BOX_SIZE >> 3), x / (BOX_SIZE >> 3)) = sum[2] / area;
            fym_bq.at<float>(y / (BOX_SIZE >> 3), x / (BOX_SIZE >> 3)) = sum[3] / area;
        }
    }

    // cout << fxp_bq;
    // cout << fxm_bq;
    // cout << fyp_bq;
    // cout << fym_bq;

    // Normalize
    normalize(fxp_bq, fxp_bq, 1, 0, NORM_L2);
    normalize(fxm_bq, fxm_bq, 1, 0, NORM_L2);
    normalize(fyp_bq, fyp_bq, 1, 0, NORM_L2);
    normalize(fym_bq, fym_bq, 1, 0, NORM_L2);

    fxp_bq.copyTo(motion_descriptor(Rect(0,                0,             BOX_SIZE >> 4, BOX_SIZE >> 4)));
    fxm_bq.copyTo(motion_descriptor(Rect(BOX_SIZE >> 4,    0,             BOX_SIZE >> 4, BOX_SIZE >> 4)));
    fyp_bq.copyTo(motion_descriptor(Rect(0,                BOX_SIZE >> 4, BOX_SIZE >> 4, BOX_SIZE >> 4)));
    fym_bq.copyTo(motion_descriptor(Rect(BOX_SIZE >> 4,    BOX_SIZE >> 4, BOX_SIZE >> 4, BOX_SIZE >> 4)));
}

void processVideo(char* videoFilename) {
    //create the capture object
    VideoCapture capture(videoFilename);
    if(!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open video file: " << videoFilename << endl;
        exit(EXIT_FAILURE);
    }
    //read input data. ESC or 'q' for quitting
    keyboard = 0;
    while( keyboard != 'q' && keyboard != 27 ){
        //read the current frame
        if(!capture.read(frame)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            exit(EXIT_FAILURE);
        }
        //update the background model
        // target_box.x = 90;  target_box.y= 0;
        target_box.x = 250;  target_box.y= 100;
        target_box.width = BOX_SIZE; target_box.height = BOX_SIZE;

        target_frame = frame(target_box);
        cvtColor(target_frame, target_frame_gray, COLOR_BGR2GRAY );
        pMOG2->apply(target_frame_gray, fgMaskMOG2);
        morphologyEx(fgMaskMOG2, fgMaskMOG2, MORPH_OPEN, kernel);

        Mat shape_descriptor(Size(BOX_SIZE >> 3, BOX_SIZE >> 3), CV_32FC1, Scalar(0));
        Mat motion_descriptor(Size(BOX_SIZE >> 3, BOX_SIZE >> 3), CV_32FC1, Scalar(0));

        cal_shape_descriptor(fgMaskMOG2, shape_descriptor);

        if (prevgray.empty() == false ) {
            // calculate optical flow
            calcOpticalFlowFarneback(prevgray, target_frame_gray, flowUmat, 0.4, 1, 12, 2, 8, 1.2, 0);
            // copy Umat container to standard Mat
            flowUmat.copyTo(flow);

            /*-------------------*/
            /* Draw optical flow */
            /*-------------------*/
            // for (int y = 0; y < target_frame_gray.rows; y += 8) {
            //     for (int x = 0; x < target_frame_gray.cols; x += 8)
            //     {
            //         // get the flow from y, x position * 10 for better visibility
            //         const Point2f flowatxy = flow.at<Point2f>(y, x) * 5;
            //         // draw line at flow direction
            //         line(target_frame, Point(x, y), Point(cvRound(x + flowatxy.x), cvRound(y + flowatxy.y)), Scalar(255,0,0));
            //         // draw initial point
            //         circle(target_frame, Point(x, y), 1, Scalar(0, 0, 0), -1);
            //     }
            // }

            cal_motion_descriptor(flow, motion_descriptor);

            target_frame_gray.copyTo(prevgray);
        } else {
            // fill previous image in case prevgray.empty() == true
            target_frame_gray.copyTo(prevgray);

        }


        //get the frame number and write it on the current frame
        stringstream ss;
        rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
                  cv::Scalar(255,255,255), -1);
        ss << capture.get(CAP_PROP_POS_FRAMES);
        string frameNumberString = ss.str();
        putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
                FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));

        //show the current frame and the fg masks
        imshow("Frame", frame);
        imshow("Target Frame", target_frame);
        imshow("FG Mask MOG 2", fgMaskMOG2);
        imshow("Shape descriptor", shape_descriptor);
        imshow("Motion descriptor", motion_descriptor);
        //get the input from the keyboard
        keyboard = (char)waitKey( 1000 );

        vector<int> a = {1,2,3,4,5};
        vector<int> b = {2,3,4};

        SLOW::fastdtw(a, b, 0);

    }
    //delete capture object
    capture.release();
}
